{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I was trying to perform an analysis for an Ecommerce business named `Alpha Stores`. I found that I was missing a location table for states in Brazil from my data. Hence I decided to Scrape the data off the link  `https://www.distancelatlong.com/country/brazil/`.\n",
        "\n",
        "This code block below performs web scraping to extract structured data from a webpage and organizes it into DataFrames for analysis:\n",
        "\n",
        "- **Import libraries**:  \n",
        "  `requests`, `BeautifulSoup`, and `pandas` are imported for HTTP requests, HTML parsing, and data manipulation, respectively.\n",
        "\n",
        "- **Initialize `details` list**:  \n",
        "  A list is created to store extracted data, though it's unused in this specific block.\n",
        "\n",
        "- **Define `url` and fetch webpage**:  \n",
        "  The URL of the target webpage (`https://www.distancelatlong.com/country/brazil/`) is defined, and `requests.get` retrieves the HTML content. BeautifulSoup parses the content into a navigable structure.\n",
        "\n",
        "- **Locate tables on the page**:  \n",
        "  `soup.find_all` identifies all `<table>` elements with the specified CSS classes (`table table-striped setBorder`) for data extraction.\n",
        "\n",
        "1. **Parse general country information (first table)**:  \n",
        "   - A dictionary, `country_info`, is populated by iterating over rows of the first table.  \n",
        "   - Labels (first column) and values (second column) are extracted and stored in key-value pairs.  \n",
        "   - A pandas DataFrame (`country_info_df`) is created to organize this data.\n",
        "\n",
        "2. **Parse distances to other countries (second table)**:  \n",
        "   - A list, `distances`, is created to store country-distance pairs.  \n",
        "   - Iterates through table rows (skipping the header) to extract the name of the country and its distance from Brazil.  \n",
        "   - Data is converted into a DataFrame (`distance_df`) with columns \"Country\" and \"Distance to Brazil.\"\n",
        "\n",
        "3. **Parse states with latitude and longitude (third table)**:  \n",
        "   - A list, `states`, is created to store state name, latitude, and longitude.  \n",
        "   - Iterates through table rows (skipping the header) to extract the respective data.  \n",
        "   - Data is organized into a DataFrame (`states_df`) with columns \"State,\" \"Latitude,\" and \"Longitude.\"\n",
        "\n",
        "- **Display extracted DataFrames**:  \n",
        "  Prints the `country_info_df`, `distance_df`, and `states_df` DataFrames to the console for review.\n",
        "\n",
        "- **Optional: Save DataFrames to CSV**:  \n",
        "  Comments indicate the option to save each DataFrame to a CSV file for further use. File names and paths can be customized as needed.\n"
      ],
      "metadata": {
        "id": "7Lc7Ado1TE0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize list to hold details\n",
        "details = []\n",
        "\n",
        "# URL to scrape\n",
        "url = 'https://www.distancelatlong.com/country/brazil/'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all the tables on the page\n",
        "tables = soup.find_all('table', class_='table table-striped setBorder')\n",
        "\n",
        "# Parse the first table (general country information)\n",
        "country_info = {}\n",
        "general_info_table = tables[0]\n",
        "for row in general_info_table.find_all('tr'):\n",
        "    cols = row.find_all('td')\n",
        "    if len(cols) == 2:\n",
        "        label = cols[0].text.strip()\n",
        "        value = cols[1].text.strip()\n",
        "        country_info[label] = value\n",
        "\n",
        "# Convert the general info into a DataFrame\n",
        "country_info_df = pd.DataFrame([country_info])\n",
        "\n",
        "# Parse the second table (distances to other countries)\n",
        "distances = []\n",
        "distance_table = tables[1]\n",
        "for row in distance_table.find_all('tr')[1:]:  # Skip header row\n",
        "    cols = row.find_all('td')\n",
        "    if len(cols) == 2:\n",
        "        country = cols[0].text.strip()\n",
        "        distance = cols[1].text.strip()\n",
        "        distances.append([country, distance])\n",
        "\n",
        "# Convert the distances to a DataFrame\n",
        "distance_df = pd.DataFrame(distances, columns=['Country', 'Distance to Brazil'])\n",
        "\n",
        "# Parse the third table (states with latitude and longitude)\n",
        "states = []\n",
        "states_table = tables[2]\n",
        "for row in states_table.find_all('tr')[1:]:  # Skip header row\n",
        "    cols = row.find_all('td')\n",
        "    if len(cols) == 3:\n",
        "        state = cols[0].text.strip()\n",
        "        latitude = cols[1].text.strip()\n",
        "        longitude = cols[2].text.strip()\n",
        "        states.append([state, latitude, longitude])\n",
        "\n",
        "# Convert the states to a DataFrame\n",
        "states_df = pd.DataFrame(states, columns=['State', 'Latitude', 'Longitude'])\n",
        "\n",
        "# Display the DataFrames\n",
        "print(\"Country Info:\")\n",
        "print(country_info_df)\n",
        "print(\"\\nDistances:\")\n",
        "print(distance_df)\n",
        "print(\"\\nStates:\")\n",
        "print(states_df)\n",
        "\n",
        "# Optionally, you can save the dataframes to CSV files:\n",
        "# country_info_df.to_csv('country_info.csv', index=False)\n",
        "# distance_df.to_csv('distances.csv', index=False)\n",
        "# states_df.to_csv('states.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCPfx_jdsgB6",
        "outputId": "11fc2406-98bf-4894-f773-e933b9cf87ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Country Info:\n",
            "    CAPITAL DIAL CODE   POPULATION           AREA COAST LINE MOBILE USERS  \\\n",
            "0  Bras√≠lia       +55  204,259,812  8,514,877 KM2   7,491 KM    1,774,725   \n",
            "\n",
            "  INTERNET USERS  \n",
            "0    120,111,118  \n",
            "\n",
            "Distances:\n",
            "         Country Distance to Brazil\n",
            "0       Paraguay            1231 km\n",
            "1        Bolivia            1271 km\n",
            "2  French Guiana            2024 km\n",
            "3       Suriname            2068 km\n",
            "4        Uruguay            2070 km\n",
            "\n",
            "States:\n",
            "                      State      Latitude     Longitude\n",
            "0                  Acre (3)  -9.070003236  -68.66997929\n",
            "1               Alagoas (5)   -9.48000405  -35.83996769\n",
            "2                 Amapa (5)  -0.039598369  -51.17998743\n",
            "3             Amazonas (16)  -3.289580873   -60.6199797\n",
            "4                Bahia (31)  -16.28000242   -39.0299797\n",
            "5                Ceara (19)   -2.89999225  -40.85002364\n",
            "6      Distrito Federal (1)  -15.78334023  -47.91605229\n",
            "7        Espirito Santo (5)  -20.85000771  -41.12998071\n",
            "8                Goias (18)  -17.73004311  -49.10998458\n",
            "9             Maranhao (20)  -5.809995505  -46.14998438\n",
            "10         Mato Grosso (13)  -15.65001504  -56.14002059\n",
            "11   Mato Grosso Do Sul (9)  -22.53000853   -55.7299681\n",
            "12        Minas Gerais (43)  -18.78000486  -42.95002466\n",
            "13                Para (26)  -1.190019105  -47.17999903\n",
            "14              Paraiba (3)  -7.019585756  -37.29000838\n",
            "15              Parana (20)  -24.08996499   -54.2699797\n",
            "16          Pernambuco (13)  -8.110010153  -35.02004358\n",
            "17                Piaui (7)  -4.820030091  -42.18001998\n",
            "18      Rio De Janeiro (12)  -22.56003253   -44.1699502\n",
            "19  Rio Grande Do Norte (7)  -5.650005271  -37.80000309\n",
            "20   Rio Grande Do Sul (31)  -30.88004148  -55.53000615\n",
            "21             Rondonia (9)  -11.64002724  -61.20999536\n",
            "22              Roraima (2)   1.816231505  -61.12767481\n",
            "23      Santa Catarina (19)  -27.23003172  -52.03001306\n",
            "24           Sao Paulo (47)  -23.65283405  -46.52781661\n",
            "25              Sergipe (2)  -11.26961058  -37.45002446\n",
            "26            Tocantins (6)  -6.319576804  -47.41998438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing the numbers that is after\n",
        "the state names in the dataset**"
      ],
      "metadata": {
        "id": "t4Vs_NWYUvR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states_df['State'] = states_df['State'].str.replace(r'\\s\\(\\d+\\)', '', regex=True)\n",
        "\n",
        "# Display the updated DataFrame\n"
      ],
      "metadata": {
        "id": "LxlqaH9R_WlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Optional: Save DataFrames to CSV**:  \n",
        "  Comments indicate the option to save each DataFrame to a CSV file for further use. File names and paths can be customized as needed.\n"
      ],
      "metadata": {
        "id": "M4A_OxWbU1F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states_df.to_csv('states.csv', index=False)"
      ],
      "metadata": {
        "id": "MGyXVgKg_YAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}